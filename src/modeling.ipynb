{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "\n",
    "## Read in Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/programming/miniconda3/envs/grainger/lib/python3.10/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: numba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n",
      "/home/programming/miniconda3/envs/grainger/lib/python3.10/site-packages/visions/backends/shared/nan_handling.py:51: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def hasna(x: np.ndarray) -> bool:\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# utility libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3 as sql\n",
    "from ydata_profiling import ProfileReport\n",
    "import modin.pandas as pd\n",
    "import modin.config as modin_config\n",
    "from utils import load_pickle_file, save_pickle_file\n",
    "from tqdm.notebook import tqdm\n",
    "modin_config.Engine.put(\"dask\")\n",
    "\n",
    "# ML libraries \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the training and testing data\n",
    "x_train = load_pickle_file('../data/x_train_vectorized.pkl')\n",
    "x_test = load_pickle_file('../data/x_test_vectorized.pkl')\n",
    "\n",
    "y_train = load_pickle_file('../data/y_train_encode.pkl')\n",
    "y_test = load_pickle_file('../data/y_test_encode.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple configs\n",
    "model_name = 'rfr_500_trees_balance_subsample_1_2_words_v2'\n",
    "training=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training:\n",
    "    rfc = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=30, \n",
    "        verbose=2,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    rfc.fit(x_train, y_train)\n",
    "\n",
    "    save_pickle_file(rfc, f'../models/{model_name}.pkl')\n",
    "\n",
    "else:\n",
    "    # load model from disk\n",
    "    rfc = load_pickle_file(f'../models/{model_name}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_array(arr:np.array, chunk_size:int):\n",
    "    \"\"\"Split array into chunks for batch predictions. Helps manage memory consumption.\n",
    "\n",
    "    Args:\n",
    "        arr (np.array): Input array of data to be predicted.\n",
    "        chunk_size (int): Size of chunk size to use.\n",
    "\n",
    "    Yields:\n",
    "        np.array: Sliced array with specified chunk\n",
    "    \"\"\"\n",
    "    for idx in range(0, arr.shape[0], chunk_size):\n",
    "        yield arr[idx: idx + chunk_size]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Predictions\n",
    "\n",
    "Collect the training and testing results and save out the files for consumption later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of the status updates for training\n",
    "rfc.set_params(verbose=0)\n",
    "\n",
    "selected_data = x_train\n",
    "chunksize = 100000\n",
    "\n",
    "\n",
    "total_iter = round(selected_data.shape[0] / chunksize)\n",
    "\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "for chunk in tqdm(split_array(selected_data, chunksize), total=total_iter):\n",
    "    preds_proba = rfc.predict_proba(chunk)\n",
    "    preds = np.argmax(preds_proba, axis=-1)\n",
    "    for pred, proba in zip(preds, preds_proba):\n",
    "        y_pred.append(pred)\n",
    "        y_pred_proba.append(proba)\n",
    "\n",
    "save_pickle_file(y_pred, f'../models/{model_name}_train_pred.pkl')\n",
    "save_pickle_file(y_pred_proba, f'../models/{model_name}_train_pred_proba.pkl')\n",
    "\n",
    "# memory management\n",
    "del y_pred\n",
    "del y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TEST SET\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c982ae158d5844d496b68cd4d346ed66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_test saved\n",
      "y_pred_proba_test\n"
     ]
    }
   ],
   "source": [
    "# get rid of the status updates for training\n",
    "print(\"STARTING TEST SET\")\n",
    "rfc.set_params(verbose=0)\n",
    "\n",
    "\n",
    "selected_data = x_test\n",
    "chunksize = 100000\n",
    "total_iter = round(selected_data.shape[0] / chunksize)\n",
    "\n",
    "y_pred_test = []\n",
    "y_pred_proba_test = []\n",
    "for chunk in tqdm(split_array(selected_data, chunksize), total=total_iter):\n",
    "    #preds = rfc.predict(chunk)\n",
    "    preds_proba = rfc.predict_proba(chunk)\n",
    "    preds = np.argmax(preds_proba, axis=-1)\n",
    "    for pred, proba in zip(preds, preds_proba):\n",
    "        y_pred_test.append(pred)\n",
    "        y_pred_proba_test.append(proba)\n",
    "\n",
    "\n",
    "\n",
    "save_pickle_file(y_pred_test, f'../models/{model_name}_test_pred_.pkl')\n",
    "print(\"y_pred_test saved\")\n",
    "save_pickle_file(y_pred_proba_test, f'../models/{model_name}_test_pred_proba.pkl')\n",
    "print('y_pred_proba_test')\n",
    "\n",
    "del y_pred_test\n",
    "del y_pred_proba_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Metrics from Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcrs_report(y_pred, y):\n",
    "    \"\"\"Report for precision recall and F1 score across the training and testing sets. \n",
    "\n",
    "    Args:\n",
    "        y_pred (np.array): Model predictions.\n",
    "        y (np.array): Original, correct, predictions.\n",
    "    \"\"\"\n",
    "    precision, recall, f1_score, support = precision_recall_fscore_support(\n",
    "        y_true=y,\n",
    "        y_pred=y_pred,\n",
    "        average='macro')\n",
    "\n",
    "    print(\"\\nMacro______\")\n",
    "    print(f\"Precision:\\t{np.round(precision, 2)}\")\n",
    "    print(f\"Recall:\\t\\t{np.round(recall, 2)}\")\n",
    "    print(f\"F1 Score:\\t{np.round(f1_score, 2)}\")\n",
    "\n",
    "    precision, recall, f1_score, support = precision_recall_fscore_support(\n",
    "        y_true=y,\n",
    "        y_pred=y_pred,\n",
    "        average='weighted')\n",
    "\n",
    "    print(\"\\nWeighted_____\")\n",
    "    print(f\"Precision:\\t{np.round(precision, 2)}\")\n",
    "    print(f\"Recall:\\t\\t{np.round(recall, 2)}\")\n",
    "    print(f\"F1 Score:\\t{np.round(f1_score, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "\n",
      "Macro______\n",
      "Precision:\t0.39\n",
      "Recall:\t\t0.46\n",
      "F1 Score:\t0.29\n",
      "\n",
      "Weighted_____\n",
      "Precision:\t0.68\n",
      "Recall:\t\t0.3\n",
      "F1 Score:\t0.34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# training metrics\n",
    "y_pred = load_pickle_file(f'../models/{model_name}_train_pred.pkl')\n",
    "y = y_train\n",
    "\n",
    "print(\"Training\")\n",
    "pcrs_report(y_pred, y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "\n",
      "Macro______\n",
      "Precision:\t0.37\n",
      "Recall:\t\t0.43\n",
      "F1 Score:\t0.28\n",
      "\n",
      "Weighted_____\n",
      "Precision:\t0.66\n",
      "Recall:\t\t0.3\n",
      "F1 Score:\t0.33\n"
     ]
    }
   ],
   "source": [
    "# testing metrics \n",
    "y_pred = load_pickle_file(f'../models/{model_name}_test_pred_.pkl')\n",
    "y = y_test\n",
    "\n",
    "print(\"Testing\")\n",
    "pcrs_report(y_pred, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grainger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
